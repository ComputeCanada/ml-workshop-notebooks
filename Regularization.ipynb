{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "### Controlling overfitting by restricting paramters\n",
    "### Making output more interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import helper\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One main use of regularization is to smooth model-nonconforming model irregularities\n",
    "\n",
    "# the most basic example of the uses of regularization\n",
    "# Least Squares linear regression has too high of a tendency to overfit to far outliers\n",
    "# Ridge regression adds a (w @ w) term to the loss\n",
    "\n",
    "\n",
    "def gen_hetroskedastic_data(num=5):\n",
    "    \"\"\"\n",
    "    Generate a linear trend with additive gaussian noise, and some masked, asymmetric \"shot\" noise\n",
    "    \"\"\"\n",
    "    X = npr.uniform(-5, 5, size=num)\n",
    "    Y = 3 + 0.5 * X\n",
    "    \n",
    "    gnoise = npr.normal(scale=1, size=num)\n",
    "    \n",
    "    shotnoise = 0* npr.uniform(-10, 10, size=num)\n",
    "    shotmask = npr.binomial(1, p=0.1, size=num)\n",
    "    \n",
    "    Y += gnoise\n",
    "    Y += shotmask * shotnoise\n",
    "    \n",
    "    return X, Y\n",
    "    \n",
    "X, Y = gen_hetroskedastic_data()\n",
    "_ = plt.scatter(X, Y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4bf2eb386542a99bef651bdaabf321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatLogSlider(value=0.1, description='alpha', max=3.0, min=-1.0, step=0.2), Output()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def fit_ridge(alpha=0.):\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X[:, np.newaxis], Y)\n",
    "    \n",
    "    X_lin = np.linspace(-5, 5, num=1000)\n",
    "    plt.scatter(X, Y, marker='+')\n",
    "    plt.plot(X_lin, model.predict(X_lin[:, np.newaxis]), color='red')\n",
    "    plt.plot(X_lin, 3 + 0.5 * X_lin, color='green')\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.gcf().set_size_inches(14, 8)\n",
    "    \n",
    "interact(fit_ridge, alpha=widgets.FloatLogSlider(min=-1, max=3, step=1/5, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The illustration above is mediocre in one dimension, but we can quantify some results in higher dimensions:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_high_d_data(useful_dim=5, dim=20, num=100):\n",
    "        \n",
    "    \n",
    "    if (useful_dim >= dim // 2):\n",
    "        print(\"Lowering useful_dim\")\n",
    "        useful_dim = dim // 2\n",
    "    \n",
    "    if (dim >= num):\n",
    "        print(\"Underdetermined system: raising number of samples!\")\n",
    "        num = dim + 1\n",
    "        \n",
    "    npr.seed(1337)\n",
    "    true_W = npr.uniform(-1, 1, size=(dim,))\n",
    "    true_W[useful_dim:] = 0\n",
    "    true_b = 3\n",
    "    \n",
    "    npr.seed(1340)\n",
    "    X = npr.uniform(-5, 5, size=(num, dim))\n",
    "    npr.seed(1338)\n",
    "    Y = X @ true_W + true_b + npr.normal(scale=1, loc=0, size=(num,))\n",
    "    \n",
    "    npr.seed(1339)\n",
    "    Xt, Xv, Yt, Yv = train_test_split(X, Y)\n",
    "    \n",
    "    return true_W, Xt, Xv, Yt, Yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4659665ca3a34127876b5808b4bb0803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='model', options=('ridge', 'lasso'), value='ridge'), FloatLogSl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# another use of regularization is to induce sparsity\n",
    "# here, L1 regularization, which penalizes sum(abs(w)), or ||w||_1, is shown:\n",
    "\n",
    "# This is useful for high dimensional data, where a small number of explanatory variables is desired\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "def train_high_d_ridge(model='ridge', alpha=0.1, useful_dim=5, dim=20, num=100):\n",
    "    \"\"\"\n",
    "    Generates data in a variable number of dimensions, only some of which are useful.\n",
    "    \"\"\"\n",
    "\n",
    "    true_W, Xt, Xv, Yt, Yv = get_high_d_data(useful_dim, dim, num)\n",
    "    \n",
    "    if model == 'ridge':\n",
    "        model = Ridge(alpha=alpha).fit(Xt, Yt)\n",
    "    else:\n",
    "        model = Lasso(alpha=alpha).fit(Xt, Yt)\n",
    "    \n",
    "    plt.scatter(np.arange(dim), true_W, label=\"True coefficients\")\n",
    "    plt.scatter(np.arange(dim), model.coef_, label=\"Predicted coefficients\")\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Weight index\")\n",
    "    plt.ylabel(\"Weight value\")\n",
    "    plt.gcf().set_size_inches(14, 8)\n",
    "    \n",
    "    print(\"Validation score: \", model.score(Xv, Yv))\n",
    "    \n",
    "interact(\n",
    "    train_high_d_ridge,\n",
    "    alpha=widgets.FloatLogSlider(min=-1, max=3, step=1/3, value=0),\n",
    "    dim=widgets.IntSlider(min=1, max=50, value=25),\n",
    "    num=widgets.IntSlider(min=1, max=50, value=25),\n",
    "    useful_dim=widgets.IntSlider(min=1, max=25, value=10),\n",
    "    model=widgets.RadioButtons(options=['ridge', 'lasso']),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
