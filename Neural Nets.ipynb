{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Bonus Content*: Neural Nets\n",
    "The new hotness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural nets use a different library ecosystem\n",
    "import keras\n",
    "import keras.layers as kl\n",
    "# MNIST is the \"generic toy dataset\" of choice for deep learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_tr, y_tr), (X_v, y_v) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what this data looks like:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr\n",
    "plt.imshow(X_tr[npr.randint(X_tr.shape[0])], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do one-hot encoding. Take labels of the form 1, 3, 6 into index-encoded\n",
    "# arrays like [0, 1, 0...]. [0, 0, 0, 1, 0...], etc.\n",
    "from keras.utils import to_categorical\n",
    "Y_tr = to_categorical(y_tr)\n",
    "Y_v = to_categorical(y_v)\n",
    "\n",
    "# otherwise normalization would do integer rounding: we don't want that!\n",
    "X_tr = x_train.astype(np.float64)\n",
    "X_v = x_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets work best with normalized data.\n",
    "\n",
    "Normalization subtracts the mean and divides by the standard deviation.\n",
    "It's often applied \"featurewise\", i.e. each pixel is normalized relative to the\n",
    "pixels in the same locaiton across images\n",
    "\n",
    "In MNIST, because some pixels are almost always 0, normalizing them would lead to value blowup. We normalize by the global average instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: how should normalization happen with the separate training and validation sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "M = X_tr.mean()\n",
    "S = X_tr.std()\n",
    "    \n",
    "X_tr -= M\n",
    "X_tr /= S\n",
    "X_v -= M\n",
    "X_v /= S\n",
    "\n",
    "# the first dimension is the number of samples\n",
    "print(X_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our first model will be a basic Fully Connected neural net\n",
    "m = keras.Sequential()\n",
    "m.add(kl.Flatten())\n",
    "m.add(kl.Dense(32, activation='relu'))\n",
    "m.add(kl.Dense(32, activation='relu'))\n",
    "# \"softmax\" is a nonlinarity that scales its vector input so that it sums to 1\n",
    "# thus allowing for (mathematically iffy, but practical) interpretation as a vector of probabilities\n",
    "m.add(kl.Dense(Y_tr.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: why do we need the Flatten() call?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Fitting model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "21376/60000 [=========>....................] - ETA: 6s - loss: 0.0654 - categorical_accuracy: 0.9803"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f35e28e006d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# deep learning models are very computationally intensive, and need to be compiled\n",
    "# and optimized for good performance\n",
    "print(\"Compiling model...\")\n",
    "m.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"Fitting model...\")\n",
    "m.fit(X_tr, Y_tr, epochs=5, batch_size=128, validation_data=(X_v, Y_v));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: think about why convolutional neural nets are a better fit for natural images. What properties of physical relaity do they exploit better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise\n",
    "- implement a convolutional neural network\n",
    "- competition! See who can get the highest validation accuracy.\n",
    "- **Exercise**: what's wrong with the line above, from a scientific standpoint. What happens when many differnet models are tried on the same small dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your advanced AI here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
